package lexer

import(
	"../regex"
	"container/list"
	"fmt"
)

const(
	NULL
)

var any string

func setup() {
	for var i uint8 = 0; i < 128; i++ {
		any += string(i)
	}
}

type Token struct {
	Type, ID, Value int
}

/*
	%D
	"letter" D= "[a-zA-Z]"
	"name_char" D= "({letter}|_)"
	"digit" D= "[0-9]"
	"white_space" D= "[\n\t ]"
	"any" D= "[" + any + "]"
	%D
	%%
	"{digit}+" { return Token{ INT, -1, 100 } }
	"{digit}+.{digit}*|{digit}*.{digit}+" { return Token{FLOAT, -1, 1.0} }
	"{any}+" { return Token{STRING} }
	"{name_char}({digit}|{name_char})*" { return Token{VARIABLE, $$, -1} }
	"int"
	"float"
	"string"
	"var"
	"class"
	"if"
	"for"
	"func"
	"="
	"=="
	"!"
	"!="
	%%
*/

func lex(input string, regexs []func(string) Token) list.List {
	var output list.List
	for regex := range regexs {
		token := regex(input)
		if token.Type != NULL {
			output.PushBack(token)
		}
	}
	return output
}

